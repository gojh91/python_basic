{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.contrib import rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.set_random_seed(333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = ('''이제 좀 구체적인 이야기를 해보죠. scikit-learn 0.18 버전에 다층 퍼셉트론(Multi-layer Perceptron)이 추가되었습니다.\n",
    "향후 CNN, RNN 모델이 추가되거나 GPU지원이 될까요? 아니요. 이미 파이썬에서 사용할 수 있는 훌륭한 딥러닝 라이브러리들이 있고\n",
    "이 분야는 매우 빠르게 변합니다. 우리가 케라스나 텐서플로를 따라잡아야 할 이유가 없습니다. GPU를 사용하는 데 필요한 패키지를 \n",
    "설치하는 일이 여전히 큰 장벽이라서 GPU 지원은 추가하지 않기로 했습니다. 또 GPU를 지원한다는 것은 근본적으로 알고리즘들을 \n",
    "밑바닥부터 다시 작성해야 한다는 뜻입니다. 다른 패키지를 사용해 쉽게 구현할 수 있는데, scikit-learn에서 굳이 이렇게 해야 할 강한 동기를\n",
    "찾지 못했습니다.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_set = list(set(sentence))\n",
    "char_dic = {w: i for i, w in enumerate(char_set)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dim = len(char_set)\n",
    "hidden_size = len(char_set)\n",
    "num_classes = len(char_set)\n",
    "sequence_length = 10  # Any arbitrary number\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = []\n",
    "Y_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 이제 좀 구체적인  -> 제 좀 구체적인 이\n",
      "100 추가되거나 GPU지 -> 가되거나 GPU지원\n",
      "200 할 이유가 없습니다 ->  이유가 없습니다.\n",
      "300 고리즘들을 \n",
      "밑바닥 -> 리즘들을 \n",
      "밑바닥부\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(sentence) - sequence_length):\n",
    "    x_str = sentence[i:i + sequence_length]\n",
    "    y_str = sentence[i + 1: i + sequence_length + 1]\n",
    "    \n",
    "    if i%100 == 0:\n",
    "        print(i, x_str, '->', y_str)\n",
    "\n",
    "    x = [char_dic[c] for c in x_str]  # x str to index\n",
    "    y = [char_dic[c] for c in y_str]  # y str to index\n",
    "\n",
    "    X_data.append(x)\n",
    "    Y_data.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = len(X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.int32, [None, sequence_length])\n",
    "Y = tf.placeholder(tf.int32, [None, sequence_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"one_hot:0\", shape=(?, 10, 153), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "X_one_hot = tf.one_hot(X, num_classes)\n",
    "print(X_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-13-7f93a31bca0b>:1: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-13-7f93a31bca0b>:2: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:At least two cells provided to MultiRNNCell are the same object and will share weights.\n"
     ]
    }
   ],
   "source": [
    "lstm_cell = rnn.BasicLSTMCell(hidden_size, state_is_tuple=True)\n",
    "multi_cells = rnn.MultiRNNCell([lstm_cell] *3, state_is_tuple=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-14-c72e086eae2f>:1: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /anaconda3/envs/test/lib/python3.7/site-packages/tensorflow/python/ops/tensor_array_ops.py:162: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "outputs, _states = tf.nn.dynamic_rnn(multi_cells, X_one_hot, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_for_fc = tf.reshape(outputs, [-1, hidden_size])\n",
    "outputs = tf.contrib.layers.fully_connected(X_for_fc, num_classes, activation_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = tf.reshape(outputs, [batch_size, sequence_length, num_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = tf.ones([batch_size, sequence_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_loss = tf.contrib.seq2seq.sequence_loss(\n",
    "    logits=outputs, targets=Y, weights=weights)\n",
    "mean_loss = tf.reduce_mean(sequence_loss)\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(mean_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(500):\n",
    "    _, l, results = sess.run(\n",
    "        [train_op, mean_loss, outputs], feed_dict={X: X_data, Y: Y_data})\n",
    "    for j, result in enumerate(results):\n",
    "        index = np.argmax(result, axis=1)\n",
    "#         print(i, j, ''.join([char_set[t] for t in index]), l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  좀 구체적인 이야기를 해보죠. scikit-learn 0.18 버전에 다층 퍼셉트론(Multi-layer Perceptron)이 추가되었습니다.\n",
      "향후 CNN, RNN 모델이 추가되거나 GPU지원이 될까요? 아니요. 이미 파이썬에서 사용할 수 있는 훌륭한 딥러닝 라이브러리들이 있고\n",
      "이 분야는 매우 빠르게 변합니다. 우리가 케라스나 텐서플로를 따라잡아야 할 이유가 없습니다. GPU를 사용하는 데 필요한 패키지를 \n",
      "설치하는 일이 여전히 큰 장벽이라서 GPU 지원은 추가하지 않기로 했습니다. 또 GPU를 지원한다는 것은 근본적으로 알고리즘들을 \n",
      "밑바닥부터 다시 작성해야 한다는 뜻입니다. 다른 패키지를 사용해 쉽게 구현할 수 있는데, scikit-learn 서 굳이 이렇게 해야 할 강한 동기를\n",
      "찾지 못했습니다."
     ]
    }
   ],
   "source": [
    "results = sess.run(outputs, feed_dict={X: X_data})\n",
    "for j, result in enumerate(results):\n",
    "    index = np.argmax(result, axis=1)\n",
    "    if j is 0:  # print all for the first result to make a sentence\n",
    "        print(''.join([char_set[t] for t in index]), end='')\n",
    "    else:\n",
    "        print(char_set[index[-1]], end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
