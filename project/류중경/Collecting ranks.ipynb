{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 나라별 유명 검색 사이트에서 선택한 나라들의 탑 순위 및 원하는 검색들의 결과 보여주는. \n",
    "\n",
    "# naver.com네이버 - 한국 \n",
    "# https://tieba.baidu.com/index.html - 중국\n",
    "# https://www.yahoo.com/ - 미국\n",
    "# https://www.yahoo.co.jp/ - 일본\n",
    "\n",
    "# 위의 각 검색사이트의 현재 검색순위1~10등, 그리고 그것을 구글에서 검색한 이미지를 같이 보여준다.\n",
    "# cvc파일로 저장한다.\n",
    "# 중국 미국 일본에서 검색한 것은 번역기로 번역한 것도 같이 보여준다.\n",
    "# 원문을 컴퓨터가 읽어주기.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gTTS\n",
      "  Downloading https://files.pythonhosted.org/packages/e6/37/f55346a736278f0eb0ae9f7edee1a61028735ef0010db68a2e6fcd0ece56/gTTS-2.0.3.tar.gz\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\envs\\study\\lib\\site-packages (from gTTS) (1.12.0)\n",
      "Collecting bs4 (from gTTS)\n",
      "  Downloading https://files.pythonhosted.org/packages/10/ed/7e8b97591f6f456174139ec089c769f89a94a1a4025fe967691de971f314/bs4-0.0.1.tar.gz\n",
      "Collecting click (from gTTS)\n",
      "  Downloading https://files.pythonhosted.org/packages/fa/37/45185cb5abbc30d7257104c434fe0b07e5a195a6847506c074527aa599ec/Click-7.0-py2.py3-none-any.whl (81kB)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\envs\\study\\lib\\site-packages (from gTTS) (2.21.0)\n",
      "Collecting gtts_token (from gTTS)\n",
      "  Downloading https://files.pythonhosted.org/packages/e7/25/ca6e9cd3275bfc3097fe6b06cc31db6d3dfaf32e032e0f73fead9c9a03ce/gTTS-token-1.1.3.tar.gz\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\programdata\\anaconda3\\envs\\study\\lib\\site-packages (from bs4->gTTS) (4.7.1)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\programdata\\anaconda3\\envs\\study\\lib\\site-packages (from requests->gTTS) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\envs\\study\\lib\\site-packages (from requests->gTTS) (2019.3.9)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in c:\\programdata\\anaconda3\\envs\\study\\lib\\site-packages (from requests->gTTS) (1.24.2)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\programdata\\anaconda3\\envs\\study\\lib\\site-packages (from requests->gTTS) (3.0.4)\n",
      "Requirement already satisfied: soupsieve>=1.2 in c:\\programdata\\anaconda3\\envs\\study\\lib\\site-packages (from beautifulsoup4->bs4->gTTS) (1.8)\n",
      "Building wheels for collected packages: gTTS, bs4, gtts-token\n",
      "  Building wheel for gTTS (setup.py): started\n",
      "  Building wheel for gTTS (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\student\\AppData\\Local\\pip\\Cache\\wheels\\ac\\d3\\52\\db6c154b20dfaab7e0b514eb5eef92cecd057e40e16fdda58b\n",
      "  Building wheel for bs4 (setup.py): started\n",
      "  Building wheel for bs4 (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\student\\AppData\\Local\\pip\\Cache\\wheels\\a0\\b0\\b2\\4f80b9456b87abedbc0bf2d52235414c3467d8889be38dd472\n",
      "  Building wheel for gtts-token (setup.py): started\n",
      "  Building wheel for gtts-token (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\student\\AppData\\Local\\pip\\Cache\\wheels\\dd\\11\\61\\33f7e51bf545e910552b2255eead2a7cd8ef54064b46dceb34\n",
      "Successfully built gTTS bs4 gtts-token\n",
      "Installing collected packages: bs4, click, gtts-token, gTTS\n",
      "Successfully installed bs4-0.0.1 click-7.0 gTTS-2.0.3 gtts-token-1.1.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gTTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pygame\n",
      "  Downloading https://files.pythonhosted.org/packages/79/b0/2fec9a5d9151c8f8e20721349950c1bde2d02b331c19e178c3d76876a218/pygame-1.9.6-cp36-cp36m-win_amd64.whl (4.3MB)\n",
      "Installing collected packages: pygame\n",
      "Successfully installed pygame-1.9.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from gtts import gTTS\n",
    "from selenium import webdriver\n",
    "new_ul_naver = []\n",
    "new_ul_yahoo = []\n",
    "naver_list = []\n",
    "baidu_list = []\n",
    "yahoo_list = []\n",
    "new_ul_yahoo = []\n",
    "yahoo_jp_list = []\n",
    "rank = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Naver searching\n",
    "NAVER_URL = \"https://www.naver.com\"\n",
    "resp_naver = requests.get(NAVER_URL)\n",
    "soup_naver = BeautifulSoup(resp_naver.content, 'html.parser')\n",
    "ul_contents_naver = soup_naver.find('div', class_='ah_roll_area PM_CL_realtimeKeyword_rolling').find('ul')\n",
    "for content in ul_contents_naver.contents:\n",
    "    if not str(content).strip():\n",
    "        continue\n",
    "    new_ul_naver.append(content)\n",
    "for li in range(0,10):\n",
    "    a_tag = new_ul_naver[li].find('a').find('span')\n",
    "    naver_list.append(a_tag.find_next().text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Baidu searching\n",
    "BAIDU_URL = \"https://tieba.baidu.com/hottopic/browse/topicList\"\n",
    "resp = requests.get(BAIDU_URL)\n",
    "temp1 = resp.json()\n",
    "temp2 = temp1.get(\"data\")\n",
    "temp3 = temp2.get(\"bang_topic\")\n",
    "temp4 = temp3.get(\"topic_list\")\n",
    "for counting in range(0,10):\n",
    "    temp5 = temp4[counting]\n",
    "    baidu_list.append(temp5.get(\"topic_name\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Yahoo searching\n",
    "YAHOO_URL = \"https://www.yahoo.com/\"\n",
    "resp = requests.get(YAHOO_URL)\n",
    "soup = BeautifulSoup(resp.content, 'html.parser')\n",
    "ul_contents = soup.find('ul', class_='Pos(r) Mt(10px)').find('li').find('ul')\n",
    "for content in ul_contents.contents:\n",
    "    if not str(content).strip():\n",
    "        continue\n",
    "    new_ul_yahoo.append(content)\n",
    "for li in new_ul_yahoo:\n",
    "    a_tag = li.find('a').find('span')\n",
    "    yahoo_list.append(a_tag.find_next().text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#yahoo_jp searching\n",
    "driver = webdriver.Chrome(\"C:\\\\Users\\\\student\\\\Downloads\\\\chromedriver_win32 (2)\\\\chromedriver.exe\")\n",
    "driver.get(\"https://search.yahoo.co.jp/realtime\")\n",
    "\n",
    "for x in range(1,3):\n",
    "    for y in range(1,6):\n",
    "        daily1 = 'daily_raking_' + str(5*(x-1) + y)\n",
    "        rank.append(daily1)\n",
    "        rank[(5*(x-1) + y - 1)] = driver.find_element_by_xpath('//*[@id=\"Te\"]/div[2]/div[' + str(x) + ']/div[' + str(y) + ']/p/a')\n",
    "        yahoo_jp_list.append(rank[(5*(x-1) + y - 1)].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "def searching_images_and_save(address, name_list, image_ad, start_from, image_ad2, saving_name):\n",
    "    for listing in range(0,10):\n",
    "        driver.get(address+ name_list[listing])\n",
    "        driver.implicitly_wait(10)\n",
    "        for counting in range(0,4):\n",
    "            elem = driver.find_element_by_xpath(image_ad+ str(counting+start_from) + image_ad2)\n",
    "            elem.screenshot_as_png\n",
    "            filename = saving_name+ str(listing)+ str(counting) +'.png'\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(elem.screenshot_as_png)\n",
    "                sleep(1)\n",
    "                \n",
    "                \n",
    "\n",
    "# searching_images_and_save(\"https://search.yahoo.co.jp/image/search?p=\", yahoo_jp_list, '//*[@id=\"gridlist\"]/div[', 1, ']','yahoo_jp_img')\n",
    "searching_images_and_save(\"https://images.search.yahoo.com/search/images?p=\", yahoo_list, '//*[@id=\"resitem-', 0, '\"]', 'yahoo_img')\n",
    "searching_images_and_save(\"http://image.baidu.com/search/index?tn=baiduimage&word=\", baidu_list, '//*[@id=\"imgid\"]/div/ul/li[', 1, ']', 'baidu_img')\n",
    "searching_images_and_save(\"https://search.naver.com/search.naver?where=image&query=\", naver_list, '//*[@id=\"_sau_imageTab\"]/div[2]/div[2]/div[', 1, ']', 'naver_img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reading_list(name_list, lg, name):\n",
    "    for ct in range(0,10):\n",
    "        text = name_list[ct]\n",
    "        tts = gTTS(text=text, lang= \"{}\".format(lg))\n",
    "        tts.save(str(name) + str(ct) +\".mp3\")\n",
    "        \n",
    "reading_list(yahoo_list, 'en', 'yahoo')\n",
    "reading_list(naver_list, 'ko', 'naver')\n",
    "reading_list(baidu_list, 'zh-cn', 'baidu')\n",
    "reading_list(yahoo_jp_list, 'ja', 'yahoo_jr')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_jp = []\n",
    "tr_y = []\n",
    "tr_b = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ct in range(0,10):\n",
    "    driver.get(\"https://translate.google.co.kr/?hl=ko\")\n",
    "    driver.implicitly_wait(10)\n",
    "    search_elem = driver.find_element_by_xpath('//*[@id=\"source\"]')\n",
    "    search_elem.send_keys(yahoo_jp_list[ct])\n",
    "    elem = driver.find_element_by_xpath('/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[2]/div[3]/div[1]/div[2]/div/span[1]/span[1]')\n",
    "    tr_jp.append(elem.text)\n",
    "for ct in range(0,10):\n",
    "    driver.get(\"https://translate.google.co.kr/?hl=ko\")\n",
    "    driver.implicitly_wait(10)\n",
    "    search_elem = driver.find_element_by_xpath('//*[@id=\"source\"]')\n",
    "    search_elem.send_keys(yahoo_list[ct])\n",
    "    elem = driver.find_element_by_xpath('/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[2]/div[3]/div[1]/div[2]/div/span[1]/span[1]')\n",
    "    tr_y.append(elem.text)\n",
    "for ct in range(0,10):\n",
    "    driver.get(\"https://translate.google.co.kr/?hl=ko\")\n",
    "    driver.implicitly_wait(10)\n",
    "    search_elem = driver.find_element_by_xpath('//*[@id=\"source\"]')\n",
    "    search_elem.send_keys(baidu_list[ct])\n",
    "    elem = driver.find_element_by_xpath('/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[2]/div[3]/div[1]/div[2]/div/span[1]/span[1]')\n",
    "    tr_b.append(elem.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Naver': naver_list, 'Baidu' : baidu_list, 'Yahoo': yahoo_list, 'Yahoo_jp': yahoo_jp_list, 'tr_jp': tr_jp, 'tr_y': tr_y, 'tr_b': tr_b},index = range(1,11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Naver</th>\n",
       "      <th>Baidu</th>\n",
       "      <th>Yahoo</th>\n",
       "      <th>Yahoo_jp</th>\n",
       "      <th>tr_jp</th>\n",
       "      <th>tr_y</th>\n",
       "      <th>tr_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>비아이</td>\n",
       "      <td>柳岩摔倒</td>\n",
       "      <td>Laura Dern</td>\n",
       "      <td>PCエンジン</td>\n",
       "      <td>PC 엔진</td>\n",
       "      <td>로라 데른</td>\n",
       "      <td>리우 얀이 쓰러졌다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>전선혜</td>\n",
       "      <td>彩礼要一万八</td>\n",
       "      <td>Khatia Buniatishvili</td>\n",
       "      <td>核戦争防止国際医師会議</td>\n",
       "      <td>핵전쟁 방지 국제 의사 회</td>\n",
       "      <td>Khatia Buniyatishvili</td>\n",
       "      <td>신부 가격은 1 만 8 천</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u20 결승</td>\n",
       "      <td>中国女排横扫波兰女排</td>\n",
       "      <td>Marianne Williamson</td>\n",
       "      <td>全裸監督</td>\n",
       "      <td>완전한 알몸 감독</td>\n",
       "      <td>마리안 윌리엄슨</td>\n",
       "      <td>폴란드 여자 대표팀, 중국 여자 배구</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>축구 결승</td>\n",
       "      <td>男子用牛油果抢银行</td>\n",
       "      <td>Marisa Tomei</td>\n",
       "      <td>たぬき開発</td>\n",
       "      <td>너구리</td>\n",
       "      <td>마리사</td>\n",
       "      <td>아보카도로 도둑질하는 남자</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>다니엘 튜더</td>\n",
       "      <td>快递员遭恶意投诉下跪</td>\n",
       "      <td>Kristin Cavallari</td>\n",
       "      <td>加藤シゲアキ</td>\n",
       "      <td>카토 시게아키</td>\n",
       "      <td>크리스틴 카발라리</td>\n",
       "      <td>택배가 악의적으로 불평을 받았다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>유권</td>\n",
       "      <td>男婴抚养27年后续</td>\n",
       "      <td>Termite Control</td>\n",
       "      <td>ペイルライダー</td>\n",
       "      <td>페일</td>\n",
       "      <td>흰개미 제어</td>\n",
       "      <td>27 년간 아기 양육</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>우크라이나</td>\n",
       "      <td>动物管理局带火朱雀吧</td>\n",
       "      <td>Anna Faris</td>\n",
       "      <td>幹子</td>\n",
       "      <td>幹子</td>\n",
       "      <td>나는 기사 야.</td>\n",
       "      <td>화재 Suzaku와 동물 행정</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>한국 우크라이나</td>\n",
       "      <td>寒门还能出贵子吗</td>\n",
       "      <td>Online MBA Degree</td>\n",
       "      <td>任天堂</td>\n",
       "      <td>닌텐도</td>\n",
       "      <td>온라인 MBA 학위</td>\n",
       "      <td>차가운 문에는 여전히 아이가있을 수 있습니까?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>유권 전선혜</td>\n",
       "      <td>找不到工作告母校</td>\n",
       "      <td>Senior Dating Sites</td>\n",
       "      <td>斉藤朱夏</td>\n",
       "      <td>사이토</td>\n",
       "      <td>수석 데이트 사이트</td>\n",
       "      <td>어머니의 학교에서 일자리를 찾을 수 없습니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2019 u20 월드컵 결승</td>\n",
       "      <td>秦明生死语者</td>\n",
       "      <td>Carli Lloyd</td>\n",
       "      <td>ルリナ</td>\n",
       "      <td>루리나</td>\n",
       "      <td>칼리 로이드</td>\n",
       "      <td>진 Mingsheng의 죽음</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Naver       Baidu                  Yahoo     Yahoo_jp  \\\n",
       "1               비아이        柳岩摔倒             Laura Dern       PCエンジン   \n",
       "2               전선혜      彩礼要一万八   Khatia Buniatishvili  核戦争防止国際医師会議   \n",
       "3            u20 결승  中国女排横扫波兰女排    Marianne Williamson         全裸監督   \n",
       "4             축구 결승   男子用牛油果抢银行           Marisa Tomei        たぬき開発   \n",
       "5            다니엘 튜더  快递员遭恶意投诉下跪      Kristin Cavallari       加藤シゲアキ   \n",
       "6                유권   男婴抚养27年后续        Termite Control      ペイルライダー   \n",
       "7             우크라이나  动物管理局带火朱雀吧             Anna Faris           幹子   \n",
       "8          한국 우크라이나    寒门还能出贵子吗      Online MBA Degree          任天堂   \n",
       "9            유권 전선혜    找不到工作告母校    Senior Dating Sites         斉藤朱夏   \n",
       "10  2019 u20 월드컵 결승      秦明生死语者            Carli Lloyd          ルリナ   \n",
       "\n",
       "             tr_jp                   tr_y                       tr_b  \n",
       "1            PC 엔진                  로라 데른                리우 얀이 쓰러졌다.  \n",
       "2   핵전쟁 방지 국제 의사 회  Khatia Buniyatishvili             신부 가격은 1 만 8 천  \n",
       "3        완전한 알몸 감독               마리안 윌리엄슨       폴란드 여자 대표팀, 중국 여자 배구  \n",
       "4              너구리                    마리사             아보카도로 도둑질하는 남자  \n",
       "5          카토 시게아키              크리스틴 카발라리         택배가 악의적으로 불평을 받았다.  \n",
       "6               페일                 흰개미 제어                27 년간 아기 양육  \n",
       "7               幹子               나는 기사 야.           화재 Suzaku와 동물 행정  \n",
       "8              닌텐도             온라인 MBA 학위  차가운 문에는 여전히 아이가있을 수 있습니까?  \n",
       "9              사이토             수석 데이트 사이트  어머니의 학교에서 일자리를 찾을 수 없습니다.  \n",
       "10             루리나                 칼리 로이드            진 Mingsheng의 죽음  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"temp.csv\", encoding=\"utf8\")\n",
    "df.to_excel(\"temp1.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 번외. 셀레니움 감추기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "options = Options()\n",
    "options.add_argument('--headless')\n",
    "driver = webdriver.Chrome(\"C:\\\\Users\\\\dty\\\\Downloads\\\\chromedriver_win32\\\\chromedriver\", options=options)\n",
    "driver.get('https://www.google.com/doodles')\n",
    "\n",
    "print('Title: \"{}\"'.format(driver.title))\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
